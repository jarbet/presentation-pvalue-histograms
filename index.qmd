---
title: 'P-value histograms'
author: "[Jaron Arbet]{style='color: steelblue;'}"
subtitle: 'Is there any signal in your study?<br>Or problems with your analysis?'
date: '2025-01-03'
format: 
  revealjs: 
    incremental: true
scrollable: TRUE
slide-number: c/t
bibliography: references.bib
embed-resources: true
---

```{r setup}
library(BoutrosLab.plotting.general);
library(fontawesome);
seed <- 1234;

colorize <- function(x, color = '#6082B6') {
#3 https://bookdown.org/yihui/rmarkdown-cookbook/font-color.html#using-an-r-function-to-write-raw-html-or-latex-code
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color,
      x)
    } else x
    }
```


## Motivation

- Project with a large number of hypothesis tests/pvalues
- Histogram of p-values gives a lot of info about your study
- Is there any signal in your study?
- Are there any problems with the analyses you did?
- Summarize the key results of [@breheny2018p]

## Hypothesis testing

. . .

**Null hypothesis ($H_0$)**

* No difference between groups
* No relationship between variables
* $\theta = \theta_0$

. . .


**Alternative hypothesis ($H_A$)**

* The groups differ
* There is a relationship between variables
* $\theta \neq \theta_0$

## What is a p-value?

. . .

![](./figures/pvalue.jpg)


## When $H_0$ is always true

Flat/uniform distribution:

```{r}
set.seed(seed);
null.pvals <- data.frame(p = runif(10000));
create.histogram(
    x = null.pvals$p,
    ylab.label = 'Percent',
    xlab.label = '10K pvalues',
    breaks = seq(0, 1, by = 0.05)
    );
```

## When $H_A$ is sometimes true

Decreasing slope from left to right:

```{r}
set.seed(seed);
n.sig <- 1000;
n.total <- 10000;
pvals <- data.frame(
    p = c(
        runif(n.sig, 0, 0.001),
        runif(n.total - n.sig)
        )
    );
create.histogram(
    x = pvals$p,
    ylab.label = 'Percent',
    xlab.label = '10K pvalues'
    );
q <- p.adjust(pvals$p, method = 'fdr');
```

## Is there any signal in the data?

* [@rogier2014] mouse study where 201 genes were tested for differential expression
* No hypothesis rejected at the 10% false discovery rate level
* However, pvalue histogram suggests a signal, but the study design was underpowered to detect it:

. . .

:::{.column-body-outset}

![](./figures/signal_lowpower.png){width=70%}
:::

## "Regular" pvalue histogram

[@breheny2018p] define a **regular** pvalue histogram as the 2 scenarios we've seen so far:

* **Flat/uniform** ($H_0$ is always true)
* **Slopes down left-to-right** ($H_A$ is sometimes true)

. . .

A regular pvalue histogram suggests no errors in your study/analysis `r fa('fas fa-circle-check')`, although you might still be underpowered

## "Irregular pvalue histogram"

[@breheny2018p] define an **irregular** pvalue histogram as any other shape, for example in [@fischl2014activity]: 

. . . 

:::{.column-body-outset} 
![](./figures/irregular_pvalue_hist.png){width=80%}
:::

* An irregular pvalue histogram suggests a problem in your study or analysis, for example:

   + Measurement error
   + Parametric assumptions are wrong
   + Correlated pvalues (not a major problem, but need special coniderations which we'll come back to)

## Formal test for signal


* Let $\tau$ be the observed number of pvalues< 0.05
* Use a 1-sided Binomial test to see if $\tau$ is greater than what we'd except assuming $H_0$ is always true
* $m$ = number of tests
* $b$ = bin width of left-most bin (e.g. b = 0.05)
* Then the 95th percentile of a $Bin(m, b)$ distribution serves as a cutoff for the test
* Thus if $\tau > Bin_{.95}(m, b)$, we have evidence for a signal

## Example

* Recall the study of [@rogier2014] where 201 genes were tested but min FDR $> 0.10$
* bin-width: $b = 0.05$
* $m$ = 201 tests
* Then $Bin_{.95}(m, b)$ =

. . .
 
```{r, echo = TRUE}
qbinom(p = 0.95, size = 201, prob = 0.05);
```

* The study observed 27 p < 0.05, which exceeds the null cutoff, thus giving evidence of signal:

. . .

:::{.column-body-outset} 
![](./figures/rogier_with_cutoff.png){width=70%}
:::

## QC test for irregular pvalue histogram

* The same idea can be used to test for departures from uniformity anywhere between 0 and 1, not only near 0
* A binwidth of 0.05 gives 20 bins, and thus a corrected $\alpha= 0.05/20 = 0.0025$, or the $Bin_{.9975}(m, b)$ percentile 

. . .

**Example:**

* Recall the study of [@fischl2014activity]
* $m$ = 23,332 tests
* bin-width: $b = 0.05$
* Bonferroni corrected null threshold is:

. . .

```{r, echo = TRUE}
qbinom(p = 0.9975, size = 23332, prob = 0.05);
```
:::{.column-body-outset}
![](./figures/irregular_hist_cutoff.png){width=70%}
:::

## Correlated pvalues

* All previous results assume the pvalues are independent
* Rarely true for cancer 'omic studies (e.g. correlated genes)

. . .

[@breheny2018p] propose a permutation method for the previous signal and QC tests that accounts for correlation:

* For example, test association between outcome $Y$ with gene expression matrix $X$
1.  Permute $Y$ to remove relationship between $Y$ and $X$ while preserving the correlation structure of $X$
2. Rerun all tests on permuted dataset and record the pvalues
    + Obtains p-values from the null distribution without assuming independence
3. Record the count in the most highest bin from (2)
4. Repeat (1-3) 1000 times
5. The permutation-corrected QC cutoff is the 95th percentile of the distribution in (4)
    + Similarly, the get the permutation-corrected signal cutoff, you'd record the number of p<0.05 in each permutation dataset, then use the 95th percentile of this distribution.

## Example:

* Unpublished gene expression study
* p-value histogram suggests a problem, but note many genes are correlated

. . .

:::{.column-body-outset}
![](./figures/unpublished_qc_problem.png){width=70%}
:::


* The permutation-corrected QC cutoff suggests there is no problem in the study:

. . .

:::{.column-body-outset}
![](./figures/permuted_qc.png){width=70%}
:::

## Summary

* **`r colorize('Flat')`** pvalue histogram suggests $H_0$ always true
* **`r colorize('Slopes down left-to-right')`** suggests $H_A$ sometimes true
    + **`r colorize('Binomial test for signal')`**: far-left bin deviate from $H_0$?
    + If no tests significant after multiple testing correction, but the Binomial test is significant for an overall signal, this suggests your study was underpowered.
* **`r colorize('Irregular histograms')`** suggest problem with analysis/study
    + **`r colorize('QC binomial test')`**: does *any* area of hist deviate from $H_0$?
    + Try a robust nonparametric method instead
    + Check measurement error or problems in study design

* **`r colorize('In practice')`**, apply the signal and QC tests assuming independence. If you exceed either threshold, try the permutation method to confirm.

## R function

:::{.column-body-outset}

```{r, echo = TRUE}
pvalue.histogram <- function(
    pvalues, # vector of pvalues
    b = 0.05, # width of each bin in histogram
    alpha = 0.05, # significance level of signal test
    ... # other args to create.histogram
    ) {
    stopifnot(all(is.numeric(pvalues)) & all(pvalues > 0) & all (pvalues < 1));
    stopifnot(length(b) == 1 & is.numeric(b) & b >= 0 & b <= 0.2);

    p.df <- data.frame(p = pvalues);
    m <- sum(!is.na(pvalues));
    signal.cutoff <- qbinom(
        p = 1 - alpha,
        size = m,
        prob = b
        );
    qc.cutoff <- qbinom(
        p = 1 - alpha / (1 / b),
        size = m,
        prob = b
        );
    BoutrosLab.plotting.general::create.histogram(
        x = p.df$p,
        ylab.label = 'Frequency',
        xlab.label = 'pvalues',
        breaks = seq(0, 1, by = b),
        type = 'count',
        abline.h = c(signal.cutoff, qc.cutoff),
        abline.col = c('red', 'blue'),
        abline.lwd = 3
        );
    }

# Example:
set.seed(123);
pvals <- c(
    runif(20, 0, 0.001),
    runif(80)
    );
pvalue.histogram(pvals);
```

**[Signal]{style='color: red;'}** and **[QC]{style='color: blue;'}** thresholds

:::

# References
